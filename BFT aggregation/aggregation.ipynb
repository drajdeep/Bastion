{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3 scikit-learn==1.2.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "y4-NEhwziIg-",
        "outputId": "43c034fc-1e63-47af-b6ef-76339626252b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3 scikit-learn-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "f2aa94826e87427c833163757585d7de"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load model parameters with compatibility check\n",
        "def load_parameters(file_path):\n",
        "    \"\"\"Load model parameters and extract only numerical parameters.\"\"\"\n",
        "    try:\n",
        "        model = joblib.load(file_path)\n",
        "\n",
        "        # Extract coefficients or parameters\n",
        "        if hasattr(model, 'coef_'):\n",
        "            params = model.coef_.flatten()\n",
        "        elif hasattr(model, 'get_params'):\n",
        "            params = np.array(list(model.get_params().values())).flatten()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model format: {file_path}\")\n",
        "\n",
        "        # Filter only numerical parameters\n",
        "        params = np.array([p for p in params if isinstance(p, (int, float, np.number))])\n",
        "\n",
        "        if len(params) == 0:\n",
        "            print(f\"⚠️ No numerical parameters found in {file_path}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        return params\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Paths to pkl files\n",
        "file_paths = [\n",
        "    'random_forest_model.pkl',\n",
        "    'lightgbm_model.pkl',\n",
        "    'model.pkl'\n",
        "]\n",
        "\n",
        "# Load all parameter vectors\n",
        "parameter_vectors = [load_parameters(fp) for fp in file_paths]\n",
        "parameter_vectors = [vec for vec in parameter_vectors if vec is not None]\n",
        "\n",
        "# Ensure consistent dimensions by padding or truncating\n",
        "max_length = max(len(vec) for vec in parameter_vectors)\n",
        "\n",
        "def pad_or_truncate(vec, length):\n",
        "    \"\"\"Pad or truncate vectors to the same length.\"\"\"\n",
        "    if len(vec) < length:\n",
        "        # Pad with zeros\n",
        "        return np.pad(vec, (0, length - len(vec)), 'constant')\n",
        "    else:\n",
        "        # Truncate\n",
        "        return vec[:length]\n",
        "\n",
        "# Standardize all parameter vectors\n",
        "parameter_vectors = [pad_or_truncate(vec, max_length) for vec in parameter_vectors]\n",
        "\n",
        "# Check if all models failed\n",
        "if not parameter_vectors:\n",
        "    print(\"❌ No valid models loaded. Check compatibility and formats.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize reputation scores\n",
        "reputation_scores = np.ones(len(parameter_vectors))\n",
        "\n",
        "# Display initial parameter vectors\n",
        "print(\"\\n--- Initial Parameter Vectors ---\")\n",
        "for i, vec in enumerate(parameter_vectors):\n",
        "    print(f\"Client {i + 1} Parameters: {vec}\")\n",
        "\n",
        "# Multi-Krum aggregation\n",
        "def multi_krum(updates, num_selected=2):\n",
        "    \"\"\"Perform Multi-Krum aggregation with display.\"\"\"\n",
        "    num_clients = len(updates)\n",
        "    scores = []\n",
        "\n",
        "    print(\"\\n--- Multi-Krum Aggregation ---\")\n",
        "\n",
        "    # Calculate distances\n",
        "    for i in range(num_clients):\n",
        "        distances = [np.linalg.norm(updates[i] - updates[j])\n",
        "                     for j in range(num_clients) if i != j]\n",
        "        scores.append(sum(sorted(distances)[:num_selected]))\n",
        "        print(f\"Client {i + 1} Distances: {distances}\")\n",
        "        print(f\"Client {i + 1} Score: {scores[-1]}\")\n",
        "\n",
        "    # Select the best vectors\n",
        "    selected_indices = np.argsort(scores)[:num_selected]\n",
        "    selected_updates = np.array([updates[i] for i in selected_indices])\n",
        "    print(\"\\nSelected Indices:\", selected_indices)\n",
        "    print(\"Selected Updates:\")\n",
        "    for idx in selected_indices:\n",
        "        print(f\"Client {idx + 1}: {updates[idx]}\")\n",
        "\n",
        "    return np.mean(selected_updates, axis=0)\n",
        "\n",
        "# Reputation-based weighting\n",
        "def reputation_weighting(updates, reputation_scores):\n",
        "    \"\"\"Apply reputation-based weighting with display.\"\"\"\n",
        "    print(\"\\n--- Reputation-Based Weighting ---\")\n",
        "\n",
        "    weighted_updates = [\n",
        "        update * rep for update, rep in zip(updates, reputation_scores)\n",
        "    ]\n",
        "\n",
        "    for i, (update, weight) in enumerate(zip(updates, reputation_scores)):\n",
        "        print(f\"Client {i + 1} Weighted Parameters: {update * weight}\")\n",
        "\n",
        "    aggregated = np.mean(weighted_updates, axis=0)\n",
        "    print(\"\\nWeighted Aggregated Parameters:\", aggregated)\n",
        "    return aggregated\n",
        "\n",
        "# Update reputation scores\n",
        "def update_reputation(updates, aggregated_update, reputation_scores, threshold=0.9, decay=0.95, boost=1.05):\n",
        "    \"\"\"Update reputation scores based on cosine similarity with display.\"\"\"\n",
        "    print(\"\\n--- Reputation Update ---\")\n",
        "\n",
        "    similarities = [cosine_similarity([update], [aggregated_update])[0][0] for update in updates]\n",
        "\n",
        "    for i, sim in enumerate(similarities):\n",
        "        if sim < threshold:\n",
        "            reputation_scores[i] *= decay  # Reduce score for deviation\n",
        "            print(f\"Client {i + 1}: Similarity = {sim:.4f} (Reduced Reputation)\")\n",
        "        else:\n",
        "            reputation_scores[i] *= boost  # Increase score for valid contribution\n",
        "            print(f\"Client {i + 1}: Similarity = {sim:.4f} (Increased Reputation)\")\n",
        "\n",
        "    # Keep scores in range [0.01, 1.0]\n",
        "    reputation_scores = np.clip(reputation_scores, 0.01, 1.0)\n",
        "    print(\"Updated Reputation Scores:\", reputation_scores)\n",
        "\n",
        "    return reputation_scores\n",
        "\n",
        "# Perform aggregation over multiple rounds\n",
        "num_rounds = 5\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    print(f\"\\n=== Round {round + 1} ===\")\n",
        "\n",
        "    # Step 1: Multi-Krum aggregation\n",
        "    aggregated_update = multi_krum(parameter_vectors)\n",
        "\n",
        "    # Step 2: Reputation-weighted aggregation\n",
        "    final_update = reputation_weighting(parameter_vectors, reputation_scores)\n",
        "\n",
        "    # Step 3: Update reputation scores\n",
        "    reputation_scores = update_reputation(parameter_vectors, aggregated_update, reputation_scores)\n",
        "\n",
        "    print(f\"\\nFinal Aggregated Parameters (Round {round + 1}):\")\n",
        "    print(final_update)\n",
        "\n",
        "print(\"\\n=== Final Result After All Rounds ===\")\n",
        "print(\"Final Reputation Scores:\", reputation_scores)\n",
        "print(\"Final Aggregated Parameters:\", final_update)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWlYjmOh0J4",
        "outputId": "85ab64ee-e954-4990-a01f-d4fe6fb01e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading lightgbm_model.pkl: No module named 'numpy._core'\n",
            "\n",
            "--- Initial Parameter Vectors ---\n",
            "Client 1 Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "=== Round 1 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 1):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 2 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 2):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 3 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 3):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 4 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 4):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 5 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 5):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Final Result After All Rounds ===\n",
            "Final Reputation Scores: [1. 1.]\n",
            "Final Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final aggregated model parameters\n",
        "output_path = 'aggregated_model.pkl'\n",
        "\n",
        "# Save the final aggregated parameters using joblib\n",
        "joblib.dump(final_update, output_path)\n",
        "print(f\"\\n✅ Aggregated model saved successfully at: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcovtyw_oa0Z",
        "outputId": "b31ced57-9d81-4d83-e76d-cf6b4ad00043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Aggregated model saved successfully at: aggregated_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "\n",
        "# Load model parameters with compatibility check\n",
        "def load_parameters(file_path):\n",
        "    \"\"\"Load model parameters and extract only numerical parameters.\"\"\"\n",
        "    try:\n",
        "        model = joblib.load(file_path)\n",
        "\n",
        "        # Extract coefficients or parameters\n",
        "        if hasattr(model, 'coef_'):\n",
        "            params = model.coef_.flatten()\n",
        "        elif hasattr(model, 'get_params'):\n",
        "            params = np.array(list(model.get_params().values())).flatten()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model format: {file_path}\")\n",
        "\n",
        "        # Filter only numerical parameters\n",
        "        params = np.array([p for p in params if isinstance(p, (int, float, np.number))])\n",
        "\n",
        "        if len(params) == 0:\n",
        "            print(f\"⚠️ No numerical parameters found in {file_path}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        return params\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Paths to pkl files\n",
        "file_paths = [\n",
        "    'random_forest_model.pkl',\n",
        "    'lightgbm_model.pkl',\n",
        "    'model.pkl'\n",
        "]\n",
        "\n",
        "# Load all parameter vectors\n",
        "parameter_vectors = [load_parameters(fp) for fp in file_paths]\n",
        "parameter_vectors = [vec for vec in parameter_vectors if vec is not None]\n",
        "\n",
        "# Ensure consistent dimensions by padding or truncating\n",
        "if parameter_vectors:\n",
        "    max_length = max(len(vec) for vec in parameter_vectors)\n",
        "\n",
        "    def pad_or_truncate(vec, length):\n",
        "        \"\"\"Pad or truncate vectors to the same length.\"\"\"\n",
        "        if len(vec) < length:\n",
        "            # Pad with zeros\n",
        "            return np.pad(vec, (0, length - len(vec)), 'constant')\n",
        "        else:\n",
        "            # Truncate\n",
        "            return vec[:length]\n",
        "\n",
        "    # Standardize all parameter vectors\n",
        "    parameter_vectors = [pad_or_truncate(vec, max_length) for vec in parameter_vectors]\n",
        "else:\n",
        "    print(\"❌ No valid models loaded. Check compatibility and formats.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize reputation scores\n",
        "reputation_scores = np.ones(len(parameter_vectors))\n",
        "\n",
        "# Display initial parameter vectors\n",
        "print(\"\\n--- Initial Parameter Vectors ---\")\n",
        "for i, vec in enumerate(parameter_vectors):\n",
        "    print(f\"Client {i + 1} Parameters: {vec}\")\n",
        "\n",
        "# Multi-Krum aggregation\n",
        "def multi_krum(updates, num_selected=2):\n",
        "    \"\"\"Perform Multi-Krum aggregation with display.\"\"\"\n",
        "    num_clients = len(updates)\n",
        "    scores = []\n",
        "\n",
        "    print(\"\\n--- Multi-Krum Aggregation ---\")\n",
        "\n",
        "    # Calculate distances\n",
        "    for i in range(num_clients):\n",
        "        distances = [np.linalg.norm(updates[i] - updates[j])\n",
        "                     for j in range(num_clients) if i != j]\n",
        "        scores.append(sum(sorted(distances)[:num_selected]))\n",
        "        print(f\"Client {i + 1} Distances: {distances}\")\n",
        "        print(f\"Client {i + 1} Score: {scores[-1]}\")\n",
        "\n",
        "    # Select the best vectors\n",
        "    selected_indices = np.argsort(scores)[:num_selected]\n",
        "    selected_updates = np.array([updates[i] for i in selected_indices])\n",
        "    print(\"\\nSelected Indices:\", selected_indices)\n",
        "    print(\"Selected Updates:\")\n",
        "    for idx in selected_indices:\n",
        "        print(f\"Client {idx + 1}: {updates[idx]}\")\n",
        "\n",
        "    return np.mean(selected_updates, axis=0)\n",
        "\n",
        "# Save model after Multi-Krum aggregation\n",
        "def save_model(parameters, round_num, save_dir='aggregated_models'):\n",
        "    \"\"\"Save the aggregated model parameters to a file.\"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    file_path = os.path.join(save_dir, f'aggregated_model_round_{round_num}.pkl')\n",
        "    joblib.dump(parameters, file_path)\n",
        "    print(f\"\\n✅ Model saved after Round {round_num}: {file_path}\")\n",
        "\n",
        "# Reputation-based weighting\n",
        "def reputation_weighting(updates, reputation_scores):\n",
        "    \"\"\"Apply reputation-based weighting with display.\"\"\"\n",
        "    print(\"\\n--- Reputation-Based Weighting ---\")\n",
        "\n",
        "    weighted_updates = [\n",
        "        update * rep for update, rep in zip(updates, reputation_scores)\n",
        "    ]\n",
        "\n",
        "    for i, (update, weight) in enumerate(zip(updates, reputation_scores)):\n",
        "        print(f\"Client {i + 1} Weighted Parameters: {update * weight}\")\n",
        "\n",
        "    aggregated = np.mean(weighted_updates, axis=0)\n",
        "    print(\"\\nWeighted Aggregated Parameters:\", aggregated)\n",
        "    return aggregated\n",
        "\n",
        "# Update reputation scores\n",
        "def update_reputation(updates, aggregated_update, reputation_scores, threshold=0.9, decay=0.95, boost=1.05):\n",
        "    \"\"\"Update reputation scores based on cosine similarity with display.\"\"\"\n",
        "    print(\"\\n--- Reputation Update ---\")\n",
        "\n",
        "    similarities = [cosine_similarity([update], [aggregated_update])[0][0] for update in updates]\n",
        "\n",
        "    for i, sim in enumerate(similarities):\n",
        "        if sim < threshold:\n",
        "            reputation_scores[i] *= decay  # Reduce score for deviation\n",
        "            print(f\"Client {i + 1}: Similarity = {sim:.4f} (Reduced Reputation)\")\n",
        "        else:\n",
        "            reputation_scores[i] *= boost  # Increase score for valid contribution\n",
        "            print(f\"Client {i + 1}: Similarity = {sim:.4f} (Increased Reputation)\")\n",
        "\n",
        "    # Keep scores in range [0.01, 1.0]\n",
        "    reputation_scores = np.clip(reputation_scores, 0.01, 1.0)\n",
        "    print(\"Updated Reputation Scores:\", reputation_scores)\n",
        "\n",
        "    return reputation_scores\n",
        "\n",
        "# Perform aggregation over multiple rounds\n",
        "num_rounds = 5\n",
        "\n",
        "for round in range(1, num_rounds + 1):\n",
        "    print(f\"\\n=== Round {round} ===\")\n",
        "\n",
        "    # Step 1: Multi-Krum aggregation\n",
        "    aggregated_update = multi_krum(parameter_vectors)\n",
        "\n",
        "    # Save the model after Multi-Krum aggregation\n",
        "    save_model(aggregated_update, round)\n",
        "\n",
        "    # Step 2: Reputation-weighted aggregation\n",
        "    final_update = reputation_weighting(parameter_vectors, reputation_scores)\n",
        "\n",
        "    # Step 3: Update reputation scores\n",
        "    reputation_scores = update_reputation(parameter_vectors, aggregated_update, reputation_scores)\n",
        "\n",
        "    print(f\"\\nFinal Aggregated Parameters (Round {round}):\")\n",
        "    print(final_update)\n",
        "\n",
        "print(\"\\n=== Final Result After All Rounds ===\")\n",
        "print(\"Final Reputation Scores:\", reputation_scores)\n",
        "print(\"Final Aggregated Parameters:\", final_update)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWCOS278qiGl",
        "outputId": "a3282753-90f6-439f-decd-165c8df8c316"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading lightgbm_model.pkl: No module named 'numpy._core'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initial Parameter Vectors ---\n",
            "Client 1 Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "=== Round 1 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "✅ Model saved after Round 1: aggregated_models/aggregated_model_round_1.pkl\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 1):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 2 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "✅ Model saved after Round 2: aggregated_models/aggregated_model_round_2.pkl\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 2):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 3 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "✅ Model saved after Round 3: aggregated_models/aggregated_model_round_3.pkl\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 3):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 4 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "✅ Model saved after Round 4: aggregated_models/aggregated_model_round_4.pkl\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 4):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Round 5 ===\n",
            "\n",
            "--- Multi-Krum Aggregation ---\n",
            "Client 1 Distances: [42.0]\n",
            "Client 1 Score: 42.0\n",
            "Client 2 Distances: [42.0]\n",
            "Client 2 Score: 42.0\n",
            "\n",
            "Selected Indices: [0 1]\n",
            "Selected Updates:\n",
            "Client 1: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "✅ Model saved after Round 5: aggregated_models/aggregated_model_round_5.pkl\n",
            "\n",
            "--- Reputation-Based Weighting ---\n",
            "Client 1 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.   0.   0.   0.]\n",
            "Client 2 Weighted Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  42.   0.   0.]\n",
            "\n",
            "Weighted Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "--- Reputation Update ---\n",
            "Client 1: Similarity = 0.9787 (Increased Reputation)\n",
            "Client 2: Similarity = 0.9819 (Increased Reputation)\n",
            "Updated Reputation Scores: [1. 1.]\n",
            "\n",
            "Final Aggregated Parameters (Round 5):\n",
            "[  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n",
            "\n",
            "=== Final Result After All Rounds ===\n",
            "Final Reputation Scores: [1. 1.]\n",
            "Final Aggregated Parameters: [  1.   0.   0.   1.   2.   0. 100.   0.  21.   0.   0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'Friday_Afternoon_DDos_CICIDS17.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# === Clean Column Names ===\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# === Drop Irrelevant Columns ===\n",
        "columns_to_drop = ['Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags',\n",
        "                   'CWE Flag Count', 'ECE Flag Count']\n",
        "\n",
        "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# === Convert all columns to float (handles mixed types)\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# === Handle Infinity and Large Values ===\n",
        "# Replace inf with NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Clip extremely large values (based on domain knowledge)\n",
        "# Adjust the threshold as needed\n",
        "threshold = 1e9  # Example threshold\n",
        "df = df.clip(-threshold, threshold)\n",
        "\n",
        "# === Handle Missing Values ===\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
        "\n",
        "# === Convert Labels to Binary ===\n",
        "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
        "\n",
        "# === Separate Features and Labels ===\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df['Label']\n",
        "\n",
        "# === Standardize the Features ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# === Split into Training and Testing Sets ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCdsb7WfYUGv",
        "outputId": "8b042c62-26a8-4ffd-c10c-f11f46342058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete.\n",
            "Training set: (158021, 72), Testing set: (67724, 72)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load model parameters with compatibility check\n",
        "def load_parameters(file_path):\n",
        "    \"\"\"Load model parameters and extract only numerical parameters.\"\"\"\n",
        "    try:\n",
        "        model = joblib.load(file_path)\n",
        "\n",
        "        # Extract coefficients or parameters\n",
        "        if hasattr(model, 'coef_'):\n",
        "            params = model.coef_.flatten()\n",
        "        elif hasattr(model, 'get_params'):\n",
        "            params = np.array(list(model.get_params().values())).flatten()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model format: {file_path}\")\n",
        "\n",
        "        # Filter only numerical parameters\n",
        "        params = np.array([p for p in params if isinstance(p, (int, float, np.number))])\n",
        "\n",
        "        if len(params) == 0:\n",
        "            print(f\"⚠️ No numerical parameters found in {file_path}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        return params\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Paths to pkl files\n",
        "file_paths = [\n",
        "    'random_forest_model.pkl',\n",
        "    'lightgbm_model.pkl',\n",
        "    'model.pkl'\n",
        "]\n",
        "\n",
        "# Load all parameter vectors\n",
        "parameter_vectors = [load_parameters(fp) for fp in file_paths]\n",
        "parameter_vectors = [vec for vec in parameter_vectors if vec is not None]\n",
        "\n",
        "# Ensure consistent dimensions by padding or truncating\n",
        "if parameter_vectors:\n",
        "    max_length = max(len(vec) for vec in parameter_vectors)\n",
        "\n",
        "    def pad_or_truncate(vec, length):\n",
        "        \"\"\"Pad or truncate vectors to the same length.\"\"\"\n",
        "        if len(vec) < length:\n",
        "            return np.pad(vec, (0, length - len(vec)), 'constant')\n",
        "        else:\n",
        "            return vec[:length]\n",
        "\n",
        "    parameter_vectors = [pad_or_truncate(vec, max_length) for vec in parameter_vectors]\n",
        "\n",
        "# Check if all models failed\n",
        "if not parameter_vectors:\n",
        "    print(\"❌ No valid models loaded. Check compatibility and formats.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize reputation scores\n",
        "reputation_scores = np.ones(len(parameter_vectors))\n",
        "\n",
        "# Multi-Krum aggregation\n",
        "def multi_krum(updates, num_selected=2):\n",
        "    \"\"\"Perform Multi-Krum aggregation with display.\"\"\"\n",
        "    num_clients = len(updates)\n",
        "    scores = []\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        distances = [np.linalg.norm(updates[i] - updates[j])\n",
        "                     for j in range(num_clients) if i != j]\n",
        "        scores.append(sum(sorted(distances)[:num_selected]))\n",
        "\n",
        "    selected_indices = np.argsort(scores)[:num_selected]\n",
        "    selected_updates = np.array([updates[i] for i in selected_indices])\n",
        "\n",
        "    return np.mean(selected_updates, axis=0)\n",
        "\n",
        "# Reputation-based weighting\n",
        "def reputation_weighting(updates, reputation_scores):\n",
        "    \"\"\"Apply reputation-based weighting.\"\"\"\n",
        "    weighted_updates = [update * rep for update, rep in zip(updates, reputation_scores)]\n",
        "    aggregated = np.mean(weighted_updates, axis=0)\n",
        "    return aggregated\n",
        "\n",
        "# Update reputation scores\n",
        "def update_reputation(updates, aggregated_update, reputation_scores, threshold=0.9, decay=0.95, boost=1.05):\n",
        "    \"\"\"Update reputation scores based on cosine similarity.\"\"\"\n",
        "    similarities = [cosine_similarity([update], [aggregated_update])[0][0] for update in updates]\n",
        "\n",
        "    for i, sim in enumerate(similarities):\n",
        "        if sim < threshold:\n",
        "            reputation_scores[i] *= decay\n",
        "        else:\n",
        "            reputation_scores[i] *= boost\n",
        "\n",
        "    reputation_scores = np.clip(reputation_scores, 0.01, 1.0)\n",
        "    return reputation_scores\n",
        "\n",
        "# Save aggregated model as pkl\n",
        "def save_aggregated_model(final_update, file_name='aggregated_model.pkl'):\n",
        "    \"\"\"Save the aggregated parameters into a .pkl file.\"\"\"\n",
        "    try:\n",
        "        joblib.dump(final_update, file_name)\n",
        "        print(f\"\\n✅ Aggregated model saved as '{file_name}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving model: {e}\")\n",
        "\n",
        "# Perform aggregation over multiple rounds\n",
        "num_rounds = 5\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    print(f\"\\n=== Round {round + 1} ===\")\n",
        "\n",
        "    # Step 1: Multi-Krum aggregation\n",
        "    aggregated_update = multi_krum(parameter_vectors)\n",
        "\n",
        "    # Step 2: Reputation-weighted aggregation\n",
        "    final_update = reputation_weighting(parameter_vectors, reputation_scores)\n",
        "\n",
        "    # Step 3: Update reputation scores\n",
        "    reputation_scores = update_reputation(parameter_vectors, aggregated_update, reputation_scores)\n",
        "\n",
        "# Save the final aggregated model\n",
        "save_aggregated_model(final_update)\n",
        "\n",
        "print(\"\\n=== Final Result After All Rounds ===\")\n",
        "print(\"Final Reputation Scores:\", reputation_scores)\n",
        "print(\"Final Aggregated Parameters saved in 'aggregated_model.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPZEUMV0dLXC",
        "outputId": "9d3b4732-7581-41e7-f9ea-00a8cf0542c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading lightgbm_model.pkl: No module named 'numpy._core'\n",
            "\n",
            "=== Round 1 ===\n",
            "\n",
            "=== Round 2 ===\n",
            "\n",
            "=== Round 3 ===\n",
            "\n",
            "=== Round 4 ===\n",
            "\n",
            "=== Round 5 ===\n",
            "\n",
            "✅ Aggregated model saved as 'aggregated_model.pkl'\n",
            "\n",
            "=== Final Result After All Rounds ===\n",
            "Final Reputation Scores: [1. 1.]\n",
            "Final Aggregated Parameters saved in 'aggregated_model.pkl'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load('aggregated_model.pkl')\n",
        "\n",
        "# Check the type\n",
        "print(type(model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zc5IFk7fEzG",
        "outputId": "f9810aee-aeaa-45ba-a35c-5d862d837c6d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# === Load the Individual RandomForest Models ===\n",
        "rf1 = joblib.load('model.pkl')\n",
        "rf2 = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# === Combine the Models into an Aggregated Model ===\n",
        "aggregated_model = VotingClassifier(\n",
        "    estimators=[('rf1', rf1), ('rf2', rf2)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# === Train the Aggregated Model ===\n",
        "aggregated_model.fit(X_train, y_train)\n",
        "\n",
        "# === Make Predictions ===\n",
        "y_pred = aggregated_model.predict(X_test)\n",
        "\n",
        "# === Evaluate the Model ===\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# === Display Results ===\n",
        "print(\"\\n=== Model Evaluation Results ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3_Kp53IfVxH",
        "outputId": "90c04f7e-250f-42f4-ae50-c9199a7edf04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Evaluation Results ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[67724]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00     67724\n",
            "\n",
            "    accuracy                           1.00     67724\n",
            "   macro avg       1.00      1.00      1.00     67724\n",
            "weighted avg       1.00      1.00      1.00     67724\n",
            "\n"
          ]
        }
      ]
    }
  ]
}